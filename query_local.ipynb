{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Load all parquet files created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- lattitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- songplay_id: long (nullable = true)\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- user_agent: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# users\n",
    "parquetFile = spark.read.parquet(\"users\")\n",
    "parquetFile.createOrReplaceTempView(\"users\")\n",
    "parquetFile.printSchema()\n",
    "\n",
    "# songs\n",
    "parquetFile = spark.read.parquet(\"songs\")\n",
    "parquetFile.createOrReplaceTempView(\"songs\")\n",
    "parquetFile.printSchema()\n",
    "\n",
    "# artists\n",
    "parquetFile = spark.read.parquet(\"artists\")\n",
    "parquetFile.createOrReplaceTempView(\"artists\")\n",
    "parquetFile.printSchema()\n",
    "\n",
    "# time \n",
    "parquetFile = spark.read.parquet(\"times\")\n",
    "parquetFile.createOrReplaceTempView(\"times\")\n",
    "parquetFile.printSchema()\n",
    "\n",
    "# songplays\n",
    "parquetFile = spark.read.parquet(\"songplays\")\n",
    "parquetFile.createOrReplaceTempView(\"songplays\")\n",
    "parquetFile.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     88|  Mohammad|Rodriguez|     M| free|\n",
      "|     75|    Joseph|Gutierrez|     M| free|\n",
      "|     29|Jacqueline|    Lynch|     F| free|\n",
      "|     68|    Jordan|Rodriguez|     F| free|\n",
      "|     69|  Anabelle|  Simpson|     F| free|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM users\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+---------+----+------------------+\n",
      "|           song_id|    title| duration|year|         artist_id|\n",
      "+------------------+---------+---------+----+------------------+\n",
      "|SOCIWDW12A8C13D406|Soul Deep|148.03546|1969|ARMJAGH1187FB546F3|\n",
      "+------------------+---------+---------+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM songs WHERE year = 1969\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+---------+---------+\n",
      "|         artist_id|                name|            location|lattitude|longitude|\n",
      "+------------------+--------------------+--------------------+---------+---------+\n",
      "|ARDR4AC1187FB371A1|Montserrat Caball...|                    |     null|     null|\n",
      "|ARMAC4T1187FB3FA4C|The Dillinger Esc...|   Morris Plains, NJ| 40.82624|-74.47995|\n",
      "|AREBBGV1187FB523D2|Mike Jones (Featu...|         Houston, TX|     null|     null|\n",
      "|ARD842G1187B997376|          Blue Rodeo|Toronto, Ontario,...| 43.64856|-79.38533|\n",
      "|AR9AWNF1187B9AB0B4|Kenny G featuring...|Seattle, Washingt...|     null|     null|\n",
      "+------------------+--------------------+--------------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM artists\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|          start_time|hour|day|week|weekday|year|month|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "|2018-11-15 11:15:...|  11| 15|  46|      5|2018|   11|\n",
      "|2018-11-15 17:42:...|  17| 15|  46|      5|2018|   11|\n",
      "|2018-11-15 19:13:...|  19| 15|  46|      5|2018|   11|\n",
      "|2018-11-15 22:35:...|  22| 15|  46|      5|2018|   11|\n",
      "|2018-11-21 01:48:...|   1| 21|  47|      4|2018|   11|\n",
      "+--------------------+----+---+----+-------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM times\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|songplay_id|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|year|month|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|          0|2018-11-21 21:56:...|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "+-----------+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM songplays\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Number of female users in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|num_Female_users|\n",
      "+----------------+\n",
      "|              55|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(DISTINCT(user_id)) AS num_Female_users \\\n",
    "        FROM users \\\n",
    "        WHERE gender = 'F'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Number of songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# does it matter a.artist_id or s.artist_id???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                name|num_songs|\n",
      "+--------------------+---------+\n",
      "|                 Clp|        2|\n",
      "|              Casual|        2|\n",
      "|Mike Jones (Featu...|        1|\n",
      "|           Andy Andy|        1|\n",
      "|Kenny G featuring...|        1|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT a.name, COUNT(s.song_id) AS num_songs \\\n",
    "        FROM artists AS a \\\n",
    "        JOIN songs AS s \\\n",
    "        ON a.artist_id = s.artist_id \\\n",
    "        GROUP BY a.artist_id, a.name \\\n",
    "        ORDER BY num_songs DESC \\\n",
    "        \").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Average number of hour users spent on listening song "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|avg_hour_spent|\n",
      "+--------------+\n",
      "|          21.0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT AVG(hour) AS avg_hour_spent FROM \\\n",
    "    (SELECT u.user_id, t.hour \\\n",
    "        FROM songplays AS ss \\\n",
    "        JOIN times AS t \\\n",
    "        ON ss.start_time = t.start_time \\\n",
    "        JOIN users AS u \\\n",
    "        ON ss.user_id = u.user_id \\\n",
    "        GROUP BY u.user_id, t.hour )\\\n",
    "        \").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Song title that were played most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+\n",
      "|         title|num_play|\n",
      "+--------------+--------+\n",
      "|Setanta matins|       1|\n",
      "+--------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT s.title, COUNT(s.song_id) AS num_play \\\n",
    "        FROM songs AS s \\\n",
    "        JOIN songplays AS ss \\\n",
    "        ON ss.song_id = s.song_id \\\n",
    "          GROUP BY ss.song_id, s.title \\\n",
    "        \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
